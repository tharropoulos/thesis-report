# LLM Code Quality Analysis & Prompt Optimization

A research thesis analyzing the quality of code generated by Large Language Models (specifically GitHub Copilot) and developing methods to optimize prompts through machine learning techniques.

## Overview

This thesis investigates the quality assessment of code generated by Large Language Models (LLMs), with a specific focus on GitHub Copilot. The research evaluates code quality metrics and develops a machine learning model to predict and optimize prompt effectiveness.

This is the LaTeX source code for the thesis document.
* For Backlogged's source code, please refer to the [Backlogged repository](https://github.com/tharropoulos/backlogged/tree/copilot-testing).
* For the machine learning model, refer to the [Prompt Performance Prediction repository](https://github.com/tharropoulos/thesis-ml).

## Key Findings

- Achieved 70.10% accuracy in predicting response quality using Random Forest and Naive Bayes algorithms
- 55.34% of model responses were evaluated positively
- Identified key patterns in consecutive positive/negative evaluations
- Developed methodology for quantitative assessment of code quality
- Analyzed model performance across different types of coding tasks (Unit Testing, Integration Testing, Backend Development)

## Repository Structure

```
thesis/
├── DOCUMENT/           # LaTeX source files
│   ├── main.tex       # Main thesis document
│   ├── chapter*.tex   # Individual chapters
│   ├── references.bib # Bibliography
│   └── ...
└── PICS/              # Figures and diagrams
    └── ...
```

## Document Chapters

1. **Introduction** - Background on LLMs and code generation
2. **Methodology** - Data collection and evaluation approach
3. **Prediction Model** - Development of prompt performance prediction model
4. **Conclusions** - Key findings and future research directions

## Building the Document

To build the thesis document:

1. Ensure you have a LaTeX distribution installed (e.g., TeX Live, MiKTeX)
2. Install required packages:
   - babel (with Greek language support)
   - amsmath, amsfonts, amssymb
   - hyperref
   - graphicx
   - natbib
   - and other packages listed in main.tex

3. Build using:
```bash
pdflatex DOCUMENT/main.tex
bibtex DOCUMENT/main
pdflatex DOCUMENT/main.tex
pdflatex DOCUMENT/main.tex
```

4. View the compiled PDF file `main.pdf`:
```bash
zathura DOCUMENT/main.pdf
```

## Research Data

The research analyzed:
- 525 prompts across 28 files
- 17 test-related files
- 11 API development files
- Evaluated responses on a scale from -2 to +2
- Tracked code modifications and revisions

## License

As this is academic research, please cite appropriately if using any findings or methodologies from this work.

## Acknowledgements

Special thanks to:
- Professor Andreas Symeonidis (Thesis Supervisor)
- Aristotle University of Thessaloniki
- ISSEL (Intelligent Systems & Software Engineering Laboratory)

## For More Information

For detailed methodology, results, and conclusions, please refer to the full thesis document. The analysis includes:
- Detailed code quality metrics
- Prompt optimization techniques
- Machine learning model development
- Statistical analysis of results
- Ethics considerations in AI-generated code
